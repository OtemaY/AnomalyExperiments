# -*- coding: utf-8 -*-
"""EfficientNet_Encode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DzMetW448BZInm-RDjUznsQ76wf6EILi

# EfficientNet-B0 with AutoEncoder Model for Anomaly Detection
"""

# Imports

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import os
import csv
import numpy as np
import random
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from PIL import Image
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score
import pandas as pd
import seaborn as sns
from datetime import datetime
import time


# EfficientNet-B0 Model Definition (Lightweight variant)
class EfficientNet_Encode(nn.Module):
    def __init__(self):
        super(EfficientNet_Encode, self).__init__()
        # Load pretrained EfficientNet-B0 as encoder
        efficientnet = models.efficientnet_b0(pretrained=True)
        self.encoder = efficientnet.features

        # Modify the first conv layer to accept 1-channel (grayscale) input.
        old_conv = self.encoder[0][0]
        new_conv = nn.Conv2d(
            in_channels=1,
            out_channels=old_conv.out_channels,
            kernel_size=old_conv.kernel_size,
            stride=old_conv.stride,
            padding=old_conv.padding,
            bias=old_conv.bias is not None
        )
        # Initialize new conv weights by averaging the weights over the RGB channels.
        new_conv.weight.data = old_conv.weight.data.mean(dim=1, keepdim=True)
        self.encoder[0][0] = new_conv

        # Lightweight Decoder: Reducing intermediate channels for efficiency.
        # For a 128x128 input, the encoder outputs a feature map of size [B, 1280, 4, 4].
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(1280, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 4x4 -> 8x8
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 8x8 -> 16x16
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # 16x16 -> 32x32
            nn.ReLU(),
            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # 32x32 -> 64x64
            nn.ReLU(),
            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),  # 64x64 -> 128x128
            nn.ReLU(),
            nn.Conv2d(8, 1, kernel_size=3, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded


# Custom Dataset Definition (remains unchanged)
class CustomImageDataset(Dataset):
    def __init__(self, root_dir, transform=None, return_filename=False):
        self.root_dir = root_dir
        self.transform = transform
        self.return_filename = return_filename
        self.image_files = [f for f in os.listdir(root_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        fname = self.image_files[idx]
        img_path = os.path.join(self.root_dir, fname)
        image = Image.open(img_path).convert("L")  # Convert to grayscale
        if self.transform:
            image = self.transform(image)
        if self.return_filename:
            return image, fname
        else:
            return image


# Define transforms (resize to 128x128 to preserve more detail)
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# Setup device (GPU if available, else CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -----------------------
# Data Loading
# -----------------------

# Training dataset: all normal images (do not need filenames)
train_data_path = "/mnt/anom_proj/data/New/train"  # Update path if needed
train_dataset = CustomImageDataset(root_dir=train_data_path, transform=transform, return_filename=False)
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Validation dataset: mix of normal and anomalous images (with filenames)
val_data_path = "/mnt/anom_proj/data/New/validation"  # Update path if needed
val_dataset = CustomImageDataset(root_dir=val_data_path, transform=transform, return_filename=True)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Test dataset: mix of normal and anomalous images (with filenames)
test_data_path = "/mnt/anom_proj/data/New/test"  # Update path if needed
test_dataset = CustomImageDataset(root_dir=test_data_path, transform=transform, return_filename=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# -----------------------
# Model Training
# -----------------------

# Instantiate the EfficientAD-S model
model = EfficientNet_Encode().to(device)
model_name = model.__class__.__name__

print(f"Training {model_name} on grayscale concrete data...")

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

train_losses = []
val_losses = []

best_val_loss = float('inf')
patience = 5
counter = 0

epochs = 30  # You can adjust this; early stopping will kick in if needed

train_start = time.time()

for epoch in range(epochs):
    model.train()
    total_train_loss = 0
    for images in train_dataloader:
        images = images.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        total_train_loss += loss.item()

    avg_train_loss = total_train_loss / len(train_dataloader)

    # Validation
    model.eval()
    total_val_loss = 0
    with torch.no_grad():
        for batch in val_dataloader:
            images, _ = batch
            images = images.to(device)
            outputs = model(images)
            loss = criterion(outputs, images)
            total_val_loss += loss.item()

    avg_val_loss = total_val_loss / len(val_dataloader)
    train_losses.append(avg_train_loss)
    val_losses.append(avg_val_loss)

    print(f"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}")

    # Early stopping check
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        counter = 0
        torch.save(model.state_dict(), "best_autoencoder.pth")
    else:
        counter += 1
        if counter >= patience:
            print(f"Early stopping triggered at epoch {epoch + 1}")
            break

train_end = time.time()
train_duration = train_end - train_start
print(f"\nTraining completed in {train_duration:.2f} seconds ({train_duration / 60:.2f} minutes)")

# -----------------------
# Loss Curves
# -----------------------

os.makedirs("plots", exist_ok=True)
plt.figure(figsize=(12, 6))
epochs_run = len(train_losses)
plt.plot(range(1, epochs_run + 1), train_losses, marker='o', label="Training Loss")
plt.plot(range(1, epochs_run + 1), val_losses, marker='o', label="Validation Loss")

# plt.plot(train_losses, label="Train Loss")
# plt.plot(val_losses, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title(f"{model.__class__.__name__} Training vs Validation Loss over" f" {epochs_run} epochs")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig(f"results/plots/{model.__class__.__name__}_loss_curve.png")
plt.xlim(0, epochs_run + 1)
# Adjust y-axis to cover a bit beyond the min and max losses
ymin = min(min(train_losses), min(val_losses)) - 0.1
ymax = max(max(train_losses), max(val_losses)) + 0.1
plt.ylim(ymin, ymax)

# -----------------------
# Threshold Calibration
# -----------------------
model.eval()
train_errors = []
with torch.no_grad():
    for images in train_dataloader:
        images = images.to(device)
        outputs = model(images)
        errors = torch.mean((outputs - images) ** 2, dim=[1, 2, 3])
        train_errors.extend(errors.cpu().numpy())

train_errors = np.array(train_errors)
threshold = train_errors.mean() + 3 * train_errors.std()
print(f"Calibrated threshold based on training data: {threshold:.6f}")

mean_val = train_errors.mean()
std_val = train_errors.std()
threshold_3 = mean_val + 3 * std_val
threshold_4 = mean_val + 4 * std_val

plt.figure(figsize=(10, 6))
plt.hist(train_errors, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
plt.axvline(mean_val, color='green', linestyle='--', linewidth=2, label=f'Mean = {mean_val:.6f}')
plt.axvline(threshold_3, color='orange', linestyle='--', linewidth=2, label=f'Mean + 3Ïƒ = {threshold_3:.6f}')
plt.axvline(threshold_4, color='red', linestyle='--', linewidth=2, label=f'Mean + 4Ïƒ = {threshold_4:.6f}')
plt.title(f"Distribution of Reconstruction Errors (Training Data) - {model.__class__.__name__}")
plt.xlabel("Reconstruction Error")
plt.ylabel("Frequency")
plt.legend()
plt.grid(True)
plt.show()


# -----------------------
# Anomaly Detection with Filenames
# -----------------------
def detect_anomalies_with_filenames(model, dataloader, threshold):
    results = []  # list of tuples: (image, filename, anomaly_flag)
    model.eval()
    with torch.no_grad():
        for batch in dataloader:
            images, filenames = batch
            images = images.to(device)
            outputs = model(images)
            loss = torch.mean((outputs - images) ** 2, dim=[1, 2, 3])
            anomaly_flags = loss > threshold
            for img, fname, flag in zip(images.cpu(), filenames, anomaly_flags.cpu().numpy()):
                results.append((img, fname, flag))
    return results


val_results = detect_anomalies_with_filenames(model, val_dataloader, threshold)
inference_start = time.time()
test_results = detect_anomalies_with_filenames(model, test_dataloader, threshold)
inference_end = time.time()
inference_duration = inference_end - inference_start
print(f"\nðŸ•’ Inference on test set completed in {inference_duration:.2f} seconds ({inference_duration / 60:.2f} minutes)")

val_anomaly_count = sum(1 for _, _, flag in val_results if flag)
test_anomaly_count = sum(1 for _, _, flag in test_results if flag)
print("Validation anomalies detected:", val_anomaly_count, "out of", len(val_dataset))
print("Test anomalies detected:", test_anomaly_count, "out of", len(test_dataset))

# Load ground truth labels CSV
labels_csv_path = "/mnt/anom_proj/data/New/labels.csv"  # Update this if needed
labels_df = pd.read_csv(labels_csv_path)
label_dict = {row['filename']: row['label'] for _, row in labels_df.iterrows() if row['split'] == 'test'}

y_true = []
y_pred = []
for _, fname, is_anomaly in test_results:
    if fname in label_dict:
        y_true.append(label_dict[fname])
        y_pred.append(int(is_anomaly))

acc = accuracy_score(y_true, y_pred)
prec = precision_score(y_true, y_pred, zero_division=0)
rec = recall_score(y_true, y_pred, zero_division=0)
f1 = f1_score(y_true, y_pred, zero_division=0)

print("\nEvaluation Metrics:")
print(f"Accuracy:  {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall:    {rec:.4f}")
print(f"F1 Score:  {f1:.4f}")

cm = confusion_matrix(y_true, y_pred)


# -----------------------
# Random Sampling and Visualization
# -----------------------
def plot_images(samples, title, save_folder="data_inspection", save_filename=None):
    os.makedirs(save_folder, exist_ok=True)
    plt.figure(figsize=(15, 3))
    for i, (img, fname, flag) in enumerate(samples):
        plt.subplot(1, len(samples), i + 1)
        plt.imshow(img.squeeze(), cmap='gray')
        plt.title(fname, fontsize=8)
        plt.axis('off')
    plt.suptitle(title)
    if save_filename is None:
        save_filename = title.replace(" ", "_") + ".png"
    save_path = os.path.join(save_folder, save_filename)
    plt.savefig(save_path, bbox_inches="tight")
    print(f"Plot saved to: {save_path}")
    plt.show()


def pick_random_samples(results, num_samples=5):
    anomalies = [res for res in results if res[2]]
    normals = [res for res in results if not res[2]]
    selected_anomalies = random.sample(anomalies, min(num_samples, len(anomalies))) if anomalies else []
    selected_normals = random.sample(normals, min(num_samples, len(normals))) if normals else []
    return selected_anomalies, selected_normals


val_anomalies, val_normals = pick_random_samples(val_results, num_samples=5)
plot_images(val_anomalies, f"{model.__class__.__name__} Validation Anomalies", save_filename=f"{model.__class__.__name__}_validation_anomalies.png")
plot_images(val_normals, f"{model.__class__.__name__} Validation Normals", save_filename=f"{model.__class__.__name__}_validation_normals.png")

test_anomalies, test_normals = pick_random_samples(test_results, num_samples=5)
plot_images(test_anomalies, f"{model.__class__.__name__} Test Anomalies", save_filename=f"{model.__class__.__name__}_test_anomalies.png")
plot_images(test_normals, f"{model.__class__.__name__} Test Normals", save_filename=f"{model.__class__.__name__}_test_normals.png")


def save_results_to_csv(results, label_dict=None, split_name="test", output_path="results"):
    os.makedirs(output_path, exist_ok=True)
    filename = os.path.join(output_path, f"{split_name}_anomaly_results.csv")
    with open(filename, mode="w", newline="") as f:
        writer = csv.writer(f)
        header = ["filename", "predicted_anomaly", "actual_label"]
        writer.writerow(header)
        for _, fname, is_anomaly in results:
            actual_label = label_dict[fname] if label_dict and fname in label_dict else "NA"
            writer.writerow([fname, int(is_anomaly), actual_label])
    print(f"Saved {split_name} results to {filename}")


save_results_to_csv(val_results, label_dict=None, split_name="validation")
save_results_to_csv(test_results, label_dict=label_dict, split_name="test")


def plot_confusion_matrix(y_true, y_pred, save_path=f"results/plots/{model.__class__.__name__}_confusion_matrix.png"):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    cm = confusion_matrix(y_true, y_pred)
    labels = ["Normal", "Anomaly"]
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
    plt.title(f"{model.__class__.__name__} Confusion Matrix")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.tight_layout()
    plt.show()


plot_confusion_matrix(y_true, y_pred)


def log_experiment_run(model, criterion, optimizer, train_dataloader, val_dataloader, test_dataloader,
                       epoch, patience, train_duration, inference_duration,
                       threshold, acc, prec, rec, f1, cm,
                       save_model=True, save_paths=True, log_csv=True):
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    model_name = model.__class__.__name__
    version_prefix = f"{model_name}_{timestamp}"
    if save_model:
        os.makedirs("models", exist_ok=True)
        model_path = f"models/{version_prefix}.pth"
        torch.save(model.state_dict(), model_path)
        print(f"Saved model to {model_path}")
        file_size_bytes = os.path.getsize(model_path)
        model_file_size_mb = round(file_size_bytes / (1024 * 1024), 2)
    else:
        model_path = "not_saved"
        model_file_size_mb = "not_saved"
    if save_paths:
        os.makedirs("results", exist_ok=True)
        cm_path = f"results/plots/confusion_matrix_{version_prefix}.png"
        plt.figure(figsize=(6, 5))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Normal", "Anomaly"],
            yticklabels=["Normal", "Anomaly"])
        plt.title(f"{model.__class__.__name__} Confusion Matrix")
        plt.xlabel("Predicted Label")
        plt.ylabel("True Label")
        plt.tight_layout()
        plt.savefig(cm_path)
        plt.close()
        print(f"Confusion matrix saved to {cm_path}")
    else:
        cm_path = "not_saved"

    model_parameters = sum(p.numel() for p in model.parameters())

    experiment_settings = {
        "version_id": version_prefix,
        "timestamp": timestamp,
        "model": model_name,
        "loss_function": criterion.__class__.__name__,
        "optimizer": optimizer.__class__.__name__,
        "learning_rate": optimizer.param_groups[0]['lr'],
        "batch_size": train_dataloader.batch_size,
        "epochs_run": epoch + 1,
        "patience": patience,
        "train_time_sec": round(train_duration, 2),
        "test_inference_time_sec": round(inference_duration, 2),
        "train_size": len(train_dataloader.dataset),
        "val_size": len(val_dataloader.dataset),
        "test_size": len(test_dataloader.dataset),
        "image_size": "128x128",
        "threshold": round(threshold, 6),
        "accuracy": round(acc, 4),
        "precision": round(prec, 4),
        "recall": round(rec, 4),
        "f1_score": round(f1, 4),
        "true_negatives": cm[0][0],
        "false_positives": cm[0][1],
        "false_negatives": cm[1][0],
        "true_positives": cm[1][1],
        "model_file": model_path,
        "confusion_matrix_path": cm_path,
        "model_parameters": model_parameters,
        "model_file_size_mb": model_file_size_mb
    }
    if log_csv:
        os.makedirs("logs", exist_ok=True)
        csv_path = "logs/experiment_log.csv"
        file_exists = os.path.isfile(csv_path)
        with open(csv_path, mode="a", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=experiment_settings.keys())
            if not file_exists:
                writer.writeheader()
            writer.writerow(experiment_settings)
        print(f"Experiment logged to {csv_path}")
    return version_prefix


log_experiment_run(
    model=model,
    criterion=criterion,
    optimizer=optimizer,
    train_dataloader=train_dataloader,
    val_dataloader=val_dataloader,
    test_dataloader=test_dataloader,
    epoch=epoch,
    patience=patience,
    train_duration=train_duration,
    inference_duration=inference_duration,
    threshold=threshold,
    acc=acc,
    prec=prec,
    rec=rec,
    f1=f1,
    cm=cm,
    save_paths=True
)
